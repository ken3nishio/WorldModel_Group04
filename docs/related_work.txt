5. 先行研究調査 I：周波数領域からのアプローチ（Adaptive Low-Pass Guidance）
FramePackが抱える「静的バイアス」と「条件画像への過剰適合」を打破するための技術として、2025年に発表された Adaptive Low-Pass Guidance (ALG) は極めて重要な示唆を与える。
5.1 ALG (Adaptive Low-Pass Guidance) の理論的背景
ALGは、Image-to-Videoモデルにおいて「動きのダイナミクスが抑制される」原因を、周波数領域の観点から分析した研究である。
研究チームは、デノイジングプロセスの初期段階（タイムステップ $T$ が大きい時）において、条件画像（Image Condition）の高周波成分がモデルに「過剰な構造的制約」を与えていることを発見した。
拡散モデルは、初期段階で全体的な構図（低周波）を決定し、終盤で詳細（高周波）を描き込む。しかし、条件画像の全周波数成分を最初から入力してしまうと、モデルは「最初から詳細を維持しなければならない」と誤認し、大きな構造変化（移動や変形、消失）を起こせなくなる。
5.2 初期デノイジング段階における低周波フィルタリングの効果
ALGの手法は非常にシンプルかつ効果的である。推論時（Inference-time）において、デノイジングの初期ステップでは条件画像にガウシアンブラーなどのローパスフィルタ（Low-Pass Filter）を適用し、高周波成分を除去した状態でモデルに入力する 。
初期ステップ: 条件画像＝ボヤけた画像（低周波のみ）。モデルは「ここに何か色の塊がある」程度に認識し、プロンプトの指示（「動く」「消える」）に従ってその塊の位置や形状を大きく変化させることができる。
後期ステップ: フィルタを徐々に弱め、オリジナルの条件画像を入力する。これにより、生成された被写体の質感やディテールは元の画像と整合するようになる。
実験結果（VBench-I2Vテスト）において、ALGを適用することで動画の「ダイナミック度（Dynamic Degree）」が平均36%向上したと報告されている 。
5.3 FramePackへの適用可能性と「消失」実現への示唆
このALGのアプローチは、FramePackの問題解決に直接的に応用可能であると考えられる。
FramePackにおいて「被写体が消えない」のは、過去の圧縮コンテキストが被写体の「高周波ディテール（存在の証拠）」を保持しすぎているからかもしれない。もし、FramePackの圧縮アルゴリズムにおいて、古いフレームほど「ローパスフィルタを強くかける（ボヤけさせる）」という処理を意図的に導入すれば、モデルは過去の厳密な位置情報に縛られなくなり、プロンプトによる「消失」指示を受け入れやすくなる可能性がある。
具体的には、FramePackの3Dパッチ化カーネルによるダウンサンプリング自体が一種のローパスフィルタとして機能しているはずだが、現状ではまだ「情報が残りすぎている」可能性がある。ALGの知見は、「さらに積極的に情報を捨てる（ボヤけさせる）」ことが、逆にダイナミックな変化を生む鍵であることを示唆している。

6. 先行研究調査 II：検索拡張による動作転送（MotionRAG）
モデル内部の知識だけで「消失」という物理的に不自然な現象を生成するのが難しい場合、外部からその「動きの正解」を持ってくるアプローチが有効である。これが MotionRAG (Motion Retrieval-Augmented Generation) である。
6.1 MotionRAGのアーキテクチャと検索ベース生成
MotionRAGは、RAG（Retrieval-Augmented Generation）の概念を動画生成に応用したものである。 ユーザーが「男が煙のように消える」というプロンプトを入力した際、モデルはまず外部のビデオデータベースから、意味的に類似した（つまり、何かが消えている）ビデオクリップを検索・取得する 。これを「Motion Exemplar（動作の模範）」と呼ぶ。
この手法の革新的な点は、生成モデルに対して「ゼロから動きを想像させる」のではなく、「この参照ビデオのような動きを、この静止画（入力画像）に適用せよ」というタスクに変換する点にある。
6.2 コンテキスト認識型動作適応（Context-Aware Motion Adaptation）
単に別の動画の動きをコピーするだけでは、被写体の形状や背景が異なるため破綻する。MotionRAGは「Context-Aware Motion Adaptation (CAMA)」モジュールを用いて、検索された動画の「動きの抽象的な特徴（Motion Prior）」のみを抽出し、それをターゲット画像の文脈に合わせて適応させる 。 これにより、「馬に乗る人」の動画の動きを、「バイクに乗る人」の画像に適用するといったクロスドメインな転送が可能になる。
6.3 物理的整合性と「外部動作プライア」の導入
FramePackが「消失」を無視する理由の一つに、学習データ内の「物体恒常性バイアス」があるとしたら、MotionRAGはそのバイアスを「外部からの強制力」で上書きする手法と言える。 検索されたビデオが明確に「物体が消える」挙動を示していれば、モデルはその強い動作信号（Motion Feature）に従わざるを得なくなる。これは、モデルの内部パラメータ（重み）に依存せず、推論時に動的に動作を注入できるため、再学習なし（Training-free）あるいは軽量なアダプタ学習のみで実現できる強みがある 。
「急激な変化」を実現したい場合、プロンプトだけでモデルを説得するよりも、「急激に変化している参照動画」を見せる方が、制御性において遥かに確実性が高いことをこの研究は示している。

7. 先行研究調査 III：ストリーミング生成と同時デノイジング（Rolling Forcing / SVI）
FramePackのような自己回帰（Autoregressive）モデルの弱点は、1フレームずつ（あるいはチャンクずつ）確定させていくプロセスにおいて、前のフレームのエラーが次のフレームに波及し、モデルが保守的になる点にある。これに対し、ストリーミング生成の枠組みで「変化」を許容する手法として Rolling Forcing および Stable Video Infinity (SVI) が挙げられる。
7.1 Rolling Forcingにおける「Joint Denoising」と因果律の緩和
Rolling Forcing は、「Joint Denoising（同時デノイジング）」という概念を導入している。 通常の自己回帰では、フレーム $N$ を生成する際、フレーム $N-1$ は既に「確定した画像（ノイズなし）」として扱われる。しかしRolling Forcingでは、複数のフレーム（例えば $N$ から $N+k$）を、異なるノイズレベルで同時にデノイジングする。 具体的には、フレーム $N$ はノイズ除去が完了しつつあるが、フレーム $N+1$ はまだノイズが多く、フレーム $N+2$ はほぼノイズのみ、という状態を維持しながらスライディングウィンドウを進める。
大動作への寄与:
この手法により、フレーム間の「厳密な因果律」が緩和される。フレーム $N$ が完全に確定する前にフレーム $N+1$ の構造が形成され始めるため、フレーム間での急激な変化（消失など）が、ノイズの中で「徐々に」準備されることになる。
FramePackのように「確定した過去」をアンカーにする手法と比較して、Rolling Forcingは「流動的な未来」を含んで生成を行うため、遷移の自由度が高い。
7.2 Stable Video Infinity (SVI) におけるエラー再利用ファインチューニング
SVI は、「Error-Recycling Fine-Tuning（エラー再利用ファインチューニング）」という独自の学習戦略を提案している。 通常、モデルはきれいな正解データ（Ground Truth）で学習されるが、推論時には自分が生成した（多少崩れた）画像を入力として次を生成しなければならない。この「学習時と推論時のギャップ（Exposure Bias）」が、長尺生成での品質低下や、変化を恐れる保守的な生成の原因となる。
SVIでは、モデル自身が生成した「エラーを含むフレーム」をあえて次の学習ステップの入力として使用し、「エラーから回復する」、あるいは「エラーを含んだ状態からでも正しく変化を続ける」能力を学習させる 。 これにより、モデルは多少の破綻や不連続性を恐れなくなり、プロンプトの指示に従って大胆な変化（Drastic Change）を起こす際のリスク（アーティファクトの発生）を許容できるようになる。
7.3 自己回帰的生成における「急激な変化」の許容メカニズム
「消失」という現象は、映像的には「被写体の崩壊」に近い。通常のモデルはこれを修正しようとして被写体を復元してしまうが、SVIのようなアプローチを取り入れたモデルであれば、「意図的な崩壊（消失）」を正当な状態遷移として受け入れられる可能性がある。
FramePackにおいても、過去の圧縮コンテキストにノイズを混ぜたり、意図的に劣化した情報を与えて訓練することで、過去への過剰な依存（静的バイアス）を軽減できるかもしれない。

8. 比較分析と実装戦略
これまでの分析を統合し、FramePackの現状と、各先行研究のアプローチを比較する。
