FramePackにおけるプロンプト無視問題の構造的要因とImage-to-Videoにおける「大動作・急激な変化」実現手法の包括的調査報告書
1. エグゼクティブサマリー
本報告書は、長尺動画生成アーキテクチャであるFramePackにおいて、「被写体の消失（disappear）」等のプロンプトが無視される現象に対し、その根本原因が「急激な変化やダイナミックな動きへの対応能力の欠如」にあるという仮説を検証し、関連する先行研究を包括的に調査したものである。
分析の結果、FramePackの中核技術である「階層的コンテキスト圧縮」および「アンチドリフティング・サンプリング」が、時間的一貫性（Temporal Consistency）を維持するために過去のフレーム情報を強力なアンカー（錨）として利用しており、これが意図的な「急激な状態変化（消失など）」を「ドリフト（エラーの蓄積）」として抑制している構造的要因であることが確認された。FramePackは計算効率と記憶の保持に特化するあまり、物理的な連続性を超えた意味的な状態遷移（存在→非存在）を阻害する「静的バイアス（Static Bias）」を増幅させている。
この課題に対し、Arxiv上の最新の先行研究（2024年〜2025年）を調査した結果、以下の3つの主要なアプローチが「Image-to-Videoにおける大きな動き（Large Motion）と急激な変化（Drastic Change）」を実現・改善する有望な手法として特定された。
周波数領域制御（Adaptive Low-Pass Guidance: ALG）: デノイジング初期段階で条件付き画像の高周波成分をフィルタリングし、画像の「構造的拘束」を緩めることで、大きな動きを許容する手法。
検索拡張生成（MotionRAG）: 外部のビデオデータベースから「消失」などの動作パターン（Motion Exemplar）を検索・取得し、その動きを対象画像に転写することで、モデル内部の静的バイアスを回避する手法。
同時デノイジングとエラー再利用（Rolling Forcing / SVI）: 複数フレームを同時にデノイジングすることでフレーム間の因果律を緩和し、また自己生成エラーを学習に取り込むことで、急激な変化に伴うアーティファクトを許容・補正する手法。
本報告書では、これらの技術的詳細を解説し、FramePackの弱点を補完するための統合的な視点を提供する。

2. 序論：長尺動画生成における「記憶」と「変化」のトレードオフ
動画生成AI、特にDiffusion Transformer（DiT）ベースのモデルにおいて、生成時間の「長さ」と「品質」の両立は最大の技術的障壁の一つである。数秒の動画生成であれば、全フレームを一度にメモリに展開し、相互の注意機構（Attention Mechanism）によって一貫性を保つことが可能である。しかし、分単位あるいは無限の長尺動画を生成する場合、メモリ制約から「スライディングウィンドウ」や「自己回帰的（Autoregressive）」な手法を取らざるを得ない。
ここで発生するのが「忘却（Forgetting）」と「ドリフト（Drifting）」という二つの相反する問題である。
忘却: 過去の文脈が失われ、登場人物の服の色が変わったり、背景が変質したりする現象。
ドリフト: 過去の文脈を重視しすぎたり、生成された微細なエラーが蓄積することで、映像が崩壊したり、逆に動きが全くなくなったり（静止画化）する現象。
FramePack は、このジレンマに対し「階層的メモリ（Hierarchical Memory）」という解を提示した。これは、直近のフレームを高解像度で保持しつつ、過去のフレームを幾何級数的に圧縮して保持することで、理論上無限のコンテキストを固定長のトークン数で扱う技術である。
しかし、ユーザーの実体験として報告されている「プロンプトによる『消失』指示の無視」は、この「記憶の保持」メカニズムが過剰に作用している可能性を示唆している。ユーザーが「被写体が消える」と指示しても、モデルが保持する「過去の記憶（被写体が存在する状態）」が強力な制約として働き、生成プロセスにおいて被写体を再描画し続けてしまうのである。
本報告書では、まずFramePackの構造的特性を詳細に分解し、なぜ「変化」が抑制されるのかを論理的に証明する。その上で、この制約を突破しうる最新の研究動向をArxivから抽出し、その有効性を分析する。

3. 仮説検証：FramePackの構造的制約と「被写体消失」の困難性
FramePackにおいて「被写体の消失」が無視されるという現象は、単なるプロンプト理解の失敗ではなく、アーキテクチャが設計上持つ「変化への抵抗力」に起因すると考えられる。ここではそのメカニズムを数理的・構造的視点から分析する。
3.1 FramePackのアーキテクチャ概観
FramePackは、HunyuanVideoやWanといった既存の高性能動画生成モデルをファインチューニングする形で適用される手法であり、その核心は「コンテキストのパッキング（Packing）」にある 。 通常の自己回帰生成では、フレーム数 $N$ が増えるにつれて、Transformerが処理すべきトークン数は線形に増加し、計算量は $O(N^2)$ で増大する。これに対し、FramePackは過去のフレーム群を重要度に応じて圧縮し、常に一定のトークン数（コンテキスト長）に収める。
3.2 階層的コンテキスト圧縮（Hierarchical Context Compression）のメカニズム
FramePackのメモリ管理は、幾何級数的な圧縮スケジュールに基づいている。最新のフレーム $f_t$ に対して、過去のフレーム $f_{t-k}$ のトークン割り当て量は、距離 $k$ に応じて減少する。具体的には、圧縮率 $\lambda$ （通常 $\lambda=2$）を用いて、過去へ遡るごとに保持する情報量を半減させていく 。
これを数式で表現すると、ある時点 $t$ における総コンテキスト量 $C$ は以下のようになる。
$$C = \sum_{k=0}^{\infty} \frac{T_{base}}{\lambda^k}$$
ここで $T_{base}$ は最新フレームに割り当てられるトークン数である。$\lambda=2$ の場合、この級数は $2 \cdot T_{base}$ に収束する。つまり、無限の過去を持つ動画であっても、計算コストは最新フレーム2枚分程度に抑えられる。
この圧縮を実現するために、FramePackは「3Dパッチ化カーネル（3D Patchifying Kernels）」を使用する 。
直近: $(1, 1, 1)$ カーネル（時間・空間ともに圧縮なし）
中期: $(2, 4, 4)$ カーネル（時間2倍、空間4倍圧縮）
長期: $(8, 16, 16)$ カーネル（時間8倍、空間16倍圧縮）
分析的洞察:
この構造が「急激な変化」を阻害する第一の要因である。
過去のフレームが圧縮されるということは、高周波成分（詳細なテクスチャや微細な動き）が失われ、低周波成分（大まかな形状、色の塊、存在感）のみが「記憶」として残ることを意味する。
「被写体が存在する」という情報は、空間的に大きな低周波情報であるため、強く圧縮されても生き残る。一方、「被写体が次の瞬間に消える」という遷移は、時間的に急峻な変化（高周波な時間変化）を要求する。
圧縮された過去のメモリ（KVキャッシュ）には「被写体がいる」という強い信号が残存しており、これに対して現在の生成ステップが「いない」状態を作ろうとしても、TransformerのAttention機構は過去の強い信号（存在）を参照してしまう。結果として、被写体はボヤけたり、幽霊のように残ったり（Ghosting）、あるいは完全に戻ってきてしまう。
3.3 アンチドリフティング・サンプリング（Anti-Drifting Sampling）の副作用
FramePackのもう一つの特徴は、エラー蓄積を防ぐための「アンチドリフティング」技術である 。これには主に以下の手法が含まれる。
アンカーフレームの先行生成: 動画の始点と終点（あるいは中間のキーフレーム）を先に生成し、その間を埋めるように生成する。
双方向コンテキスト（Bi-directional Context）: 過去だけでなく未来のフレームも参照して現在を生成する。
反転サンプリング（Inverted Sampling）: Image-to-Videoにおいて、最終フレームから逆順に生成する、あるいは最終的な「到達点」を仮定して生成する 。
分析的洞察:
「消失」プロンプトにおいて、このアンチドリフティング機構が逆効果となるケースがある。
もしモデルが「被写体は消えないものだ（物体恒常性）」という一般的な物理法則を事前学習で強く持っている場合、アンカーフレーム（例えば終点）を生成する際、プロンプトの「消える」という指示よりも、学習された「物体は急には消えない」というバイアスが優先される可能性が高い。
一度「被写体が存在する終点フレーム」がアンカーとして生成されてしまうと、その間を埋める生成プロセス（In-painting / Interpolation）は、整合性を保つために被写体を描画し続けなければならなくなる。
つまり、アンチドリフティング機構は「一貫性の強制」装置であり、これは「意図的な不連続性（消失）」とは対立する概念である。
3.4 TransformerにおけるKVキャッシュと「静的バイアス」の永続化
FramePackの実装（GitHub 等の議論参照）において、TransformerのKey-Value（KV）キャッシュは、過去の全ての圧縮フレームの特徴量を保持している。 Attention機構は、現在のクエリ（$Q$）に対して、メモリ内のキー（$K$）との類似度を計算し、バリュー（$V$）を取り出す。
$$\text{Attention}(Q, K, V) = \text{Softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$
ここで、メモリ内の $K$ の大半が「被写体が存在する過去のフレーム」由来である場合、Attentionスコアはそれらのフレームに高く配分される。これを「Attention Sink」現象 の変種として捉えることができる。特にFramePackのように過去を圧縮して「要約」している場合、その要約は「ここに人物がいた」というセマンティックな情報を強く保持する傾向がある。 「消失」を実現するには、この過去の $K$ に対するAttentionを遮断するか、プロンプトによる指示（Cross-Attention）がSelf-Attention（過去の映像参照）を凌駕する必要がある。しかし、多くの動画生成モデルでは、映像の一貫性を保つためにSelf-Attentionの重みが高く設定されているため、プロンプトの指示が無視されやすい 。
3.5 論理的帰結：なぜFramePackは「消失」を「エラー」と誤認するのか
以上の構造分析から、FramePackにおける「消失プロンプト無視」のメカニズムは以下のように結論付けられる。
情報の圧縮保存: 被写体の存在情報は低周波成分として圧縮メモリ内に強固に保存される。
変化の抑制: アンチドリフティング機構は、フレーム間の急激な変化を「ドリフト（エラー）」として検出し、補正しようとする。
セマンティックな慣性: 「消失」という事象は、ピクセルレベルでは急激な変化であり、セマンティックレベルでは不連続性である。FramePackは「連続性と一貫性」を最優先目的関数として設計されているため、この不連続性を許容できない。
したがって、ユーザーの「急激な変化やダイナミックな動きに対応できない」という仮説は、FramePackの設計思想（一貫性・メモリ効率・エラー抑制）そのものに由来する必然的な副作用であり、論理的に極めて妥当であると言える。

4. 基盤モデル（HunyuanVideo/Wan）に内在する静的バイアスの影響
FramePackは単独のモデルではなく、HunyuanVideoやWanなどのベースモデルに適用される技術である 。したがって、ベースモデルが持つ特性もこの問題に深く関与している。
4.1 学習データの偏りと「動きの抑制」
HunyuanVideo等の大規模モデルは、Web上の膨大な動画データセットで学習されている。しかし、高品質な動画データセットには、以下のようなバイアスが含まれていることが多い 。
カメラワークの安定性: プロが撮影した映像や映画のクリップは、手ブレがなく、動きが滑らかであることが多い。
2Dアニメーションの影響: データセットに含まれるアニメーション素材の中には、背景が静止画で口だけ動くような「リミテッド・アニメーション」が多く含まれる場合があり、これがモデルに「背景や主要被写体は動かないもの」というバイアスを植え付ける 。
静的シーンの優位性: 風景映像やトーク映像など、動きの少ないデータの方が学習が容易であり、損失関数が低下しやすいため、モデルは「動かないこと」を安全な戦略として学習する傾向がある。
この「静的バイアス（Static Bias）」は、FramePackによる長尺生成時に増幅される。短い動画であれば多少の動きが生成できても、長くなるとモデルは「安全策」を取り、動きを収束させてしまう（いわゆる "Body shaking in place" 現象 ）。
4.2 Flow Matchingと条件付き画像の漏洩（Conditional Image Leakage）
HunyuanVideoなどの最新モデルは、拡散モデルの一種である「Flow Matching」を採用している場合が多い。また、Image-to-Videoタスクにおいては、最初のフレーム（条件付き画像）を入力として与える。
ここでの問題は「条件付き画像の漏洩（Conditional Image Leakage）」である 。 モデルは、ノイズから画像を復元する際、与えられた条件画像（1フレーム目）を過度に参照してしまう。特にデノイジングの初期段階（ノイズが多い段階）で、本来なら大まかな動きや構図を決定すべきところに、条件画像の「高周波ディテール（細かい模様や輪郭）」が漏れ出してしまう。 これにより、1フレーム目のピクセル配置が以降のフレームにも強く拘束され、被写体がその場に「張り付く」現象が発生する。ユーザーが「右に移動して消える」と指示しても、1フレーム目の位置情報が強すぎて動けないのである。
4.3 FramePackファインチューニングによるバイアスの増幅
FramePackによるファインチューニングは、基本的に「長いコンテキストを一貫性を保って生成する」能力を強化するものである。これは、ベースモデルが持っている「静的バイアス」や「条件画像への依存」を、さらに時間軸方向に引き伸ばして強化する作用を持つ。
つまり、FramePackは「一貫性を保つこと」には成功しているが、その「一貫性」の定義が「変化しないこと（静止）」に偏ってしまっているのが現状である。

5. 先行研究調査 I：周波数領域からのアプローチ（Adaptive Low-Pass Guidance）
FramePackが抱える「静的バイアス」と「条件画像への過剰適合」を打破するための技術として、2025年に発表された Adaptive Low-Pass Guidance (ALG) は極めて重要な示唆を与える。
5.1 ALG (Adaptive Low-Pass Guidance) の理論的背景
ALGは、Image-to-Videoモデルにおいて「動きのダイナミクスが抑制される」原因を、周波数領域の観点から分析した研究である。
研究チームは、デノイジングプロセスの初期段階（タイムステップ $T$ が大きい時）において、条件画像（Image Condition）の高周波成分がモデルに「過剰な構造的制約」を与えていることを発見した。
拡散モデルは、初期段階で全体的な構図（低周波）を決定し、終盤で詳細（高周波）を描き込む。しかし、条件画像の全周波数成分を最初から入力してしまうと、モデルは「最初から詳細を維持しなければならない」と誤認し、大きな構造変化（移動や変形、消失）を起こせなくなる。
5.2 初期デノイジング段階における低周波フィルタリングの効果
ALGの手法は非常にシンプルかつ効果的である。推論時（Inference-time）において、デノイジングの初期ステップでは条件画像にガウシアンブラーなどのローパスフィルタ（Low-Pass Filter）を適用し、高周波成分を除去した状態でモデルに入力する 。
初期ステップ: 条件画像＝ボヤけた画像（低周波のみ）。モデルは「ここに何か色の塊がある」程度に認識し、プロンプトの指示（「動く」「消える」）に従ってその塊の位置や形状を大きく変化させることができる。
後期ステップ: フィルタを徐々に弱め、オリジナルの条件画像を入力する。これにより、生成された被写体の質感やディテールは元の画像と整合するようになる。
実験結果（VBench-I2Vテスト）において、ALGを適用することで動画の「ダイナミック度（Dynamic Degree）」が平均36%向上したと報告されている 。
5.3 FramePackへの適用可能性と「消失」実現への示唆
このALGのアプローチは、FramePackの問題解決に直接的に応用可能であると考えられる。
FramePackにおいて「被写体が消えない」のは、過去の圧縮コンテキストが被写体の「高周波ディテール（存在の証拠）」を保持しすぎているからかもしれない。もし、FramePackの圧縮アルゴリズムにおいて、古いフレームほど「ローパスフィルタを強くかける（ボヤけさせる）」という処理を意図的に導入すれば、モデルは過去の厳密な位置情報に縛られなくなり、プロンプトによる「消失」指示を受け入れやすくなる可能性がある。
具体的には、FramePackの3Dパッチ化カーネルによるダウンサンプリング自体が一種のローパスフィルタとして機能しているはずだが、現状ではまだ「情報が残りすぎている」可能性がある。ALGの知見は、「さらに積極的に情報を捨てる（ボヤけさせる）」ことが、逆にダイナミックな変化を生む鍵であることを示唆している。
