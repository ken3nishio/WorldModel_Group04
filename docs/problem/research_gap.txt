長尺動画生成における文脈的持続性と意味的遷移のダイナミクス：FramePackを起点とした『記憶による変化の抑制』に関する包括的研究報告書
エグゼクティブサマリー
動画生成技術の進化は、数秒のクリップ生成から、無限に続く高忠実度なストリーミング生成へとパラダイムシフトを遂げている。この移行の中心にあるのが、時間的一貫性と計算効率を両立させる「次フレーム（または次セクション）予測」アーキテクチャである。特に「FramePack」は、コンテキストパッキング（Context Packing）技術を用いることで、13Bパラメータ規模のモデルを一般的な消費者向けGPU（VRAM 6GB程度）で動作させつつ、従来の課題であった「忘却（Forgetting）」と「ドリフト（Drifting）」を抑制することに成功した 。しかし、時間的安定性を確保するために強化された「記憶」メカニズムは、同時に新たな課題を生み出している。それが本報告書で定義する「記憶による変化の抑制（Inhibition of Change due to Memory）」である。これは、モデルが過去の文脈に過度に適応することで、シーン遷移やオブジェクトの消失といった意図的な意味的変化（Semantic Shift）を「エラー」や「ドリフト」として排除してしまう現象を指す。
本報告書は、FramePackをケーススタディとしつつ、長尺動画生成における「記憶」と「変化」の対立構造を技術的・理論的側面から徹底的に分析するものである。具体的には、研究における「リサーチギャップ（Research Gap）」の定義（方法論的、知識的、経験的ギャップ等）に基づき、Arxiv上の最新論文（2024-2026年）を網羅的に調査した。特に、シーン遷移（Scene Transition）、選択的忘却（Selective Forgetting）、動的メモリ管理（Dynamic Memory Management）に関する未解決問題を体系化し、それらを解決するための新規性ある研究テーマを提案する。

第1章：序論 - 動画生成における記憶のパラドックス
1.1 長尺動画生成の台頭とメモリの壁
近年の動画生成モデル（Sora, HunyuanVideo, Wan等）は、驚異的な画質と物理演算のシミュレーション能力を示しているが、その多くは数秒から十数秒の生成に限定されている。物語性のあるコンテンツや、実世界シミュレータとしての応用を考えた場合、分単位あるいは時間単位の連続的な動画生成が不可欠となる。しかし、Transformerベースのアーキテクチャにおいて、アテンション機構の計算量はシーケンス長（フレーム数）の二乗に比例して増大するため、単純なコンテキストの拡張は計算資源的に破綻する 。
1.2 FramePackのアプローチとその副作用
この計算ボトルネックに対する解として提案されたのが、FramePackである。FramePackは、過去のフレーム群をその重要度に応じて圧縮し、固定長のコンテキストとしてTransformerに入力することで、動画の長さに関わらず計算コストを一定（画像生成と同等レベル）に保つ 。これにより、13BモデルであってもラップトップGPUで数千フレームの生成が可能となった。
しかし、FramePackが採用する「Anti-Drifting（ドリフト防止）」機構は、過去の文脈を強力に保持し、生成される現在フレームが過去の延長線上にあることを強制する。これは「歩行」や「ダンス」といった連続的な動作の維持には極めて有効であるが、「シーンの切り替え（カット）」や「物体の消失」といった不連続な変化においては、過去の記憶が足かせとなり、変化を阻害する要因となる。本報告書では、この現象を「記憶による変化の抑制」と定義し、その克服こそが次世代の動画生成における最大の課題であると位置づける。

第2章：理論的枠組みとリサーチギャップの定義
研究の空白（リサーチギャップ）を特定するためには、まずその定義を明確にし、既存の文献がどの領域をカバーし、どこに欠落があるのかを構造的に把握する必要がある。
2.1 リサーチギャップの分類学
学術的研究において、リサーチギャップは単なる「未着手」の領域ではなく、特定の知識体系における欠陥や矛盾として定義される。本報告書では、以下の定義に基づき分析を行う 。
ギャップの種類
定義
FramePack・長尺動画生成における文脈
知識的ギャップ (Knowledge Gap)
特定の現象に関する情報や理解が欠如している状態。
「意味的慣性（Semantic Inertia）」のメカニズム解明。なぜモデルはプロンプトが変わっても古いシーンを描き続けるのか、その内部表現の変化に関する知見の欠如。
方法論的ギャップ (Methodological Gap)
既存の研究手法や手続きの限界により、信頼性や精度に影響が出る状態。
シーン遷移を評価するためのデータセットや、意図的な「忘却」を学習させるためのトレーニング手法（損失関数設計）の不足。
経験的ギャップ (Empirical Gap)
実証的なデータや評価が不足している、あるいは特定の文脈での検証がなされていない状態。
「カット」を含むマルチショット生成におけるFramePackの挙動検証。連続生成には強いが、不連続性に対する耐性は実証データが乏しい。
理論的ギャップ (Theoretical Gap)
既存の理論やモデルでは説明できない現象、あるいは新しい概念モデルが必要な状態。
「アテンションシンク（Attention Sink）」現象と長期的崩壊（Sink-Collapse）の関係性。RoPE等の位置埋め込みが記憶の固着に与える理論的限界。
証拠的ギャップ (Evidence/Contradictory Gap)
異なる研究結果間に矛盾が存在する状態。
「コンテキスト長を伸ばすべき」とする主張（文脈重視）と、「圧縮・忘却すべき」とする主張（効率・変化重視）の対立とトレードオフの未解決。

2.2 次フレーム予測における安定性と可塑性のジレンマ
認知科学およびニューラルネットワーク研究において、「安定性と可塑性のジレンマ（Stability-Plasticity Dilemma）」は古典的かつ根本的な課題である 。システムは、以前に学習した知識（ここでは過去のフレーム情報）を保持する「安定性」と、新しい入力（新しいプロンプトやシーン展開）に適応する「可塑性」を同時に満たす必要がある。
FramePackを含む自己回帰的（Autoregressive）な動画生成モデルにおいて、このジレンマは以下のように顕在化する：
過剰な安定性（Inhibition of Change）: 過去のフレームへのアテンションが強すぎると、新しいプロンプトによる指示（例：「男が消える」）が無視され、過去の慣性（男が存在し続ける）が優先される。
過剰な可塑性（Drifting/Forgetting）: 過去のフレームへのアテンションが弱すぎると、キャラクターの同一性や背景の一貫性が失われ、映像が崩壊する 。
既存研究の多くは「ドリフト（崩壊）」を防ぐための安定性強化に注力しており、その副作用としての「変化の抑制」に対する解決策が欠落している。これが本研究が着目する包括的なギャップである。

第3章：FramePackアーキテクチャの深層分析と限界
3.1 コンテキストパッキング（Context Packing）のメカニズム
FramePackの核心は、入力フレーム群をその重要度（Importance）に基づいて圧縮・選択し、固定長のコンテキストに詰め込む（Pack）点にある 。通常、重要度は時間的近接性（Temporal Proximity）によって定義され、直近のフレームほど詳細に、過去のフレームほど粗く（あるいは間引いて）保持される。
メモリ管理とバッチ処理の革新
特筆すべきは、FramePackが動画生成を画像生成と同様のバッチサイズで学習可能にした点である 。従来の動画拡散モデルは、時間軸方向のアテンション計算によりVRAMを大量に消費するため、バッチサイズを極端に小さくせざるを得なかった。しかし、FramePackは「次フレーム（セクション）」の予測に必要な情報を圧縮された固定長トークンとして扱うため、13Bモデルであってもバッチサイズ64（8xA100環境）での学習を実現している 。
逆方向サンプリングによるドリフト防止
さらにFramePackは、サンプリング時に時間軸を逆転させる（未来のターゲットフレームを先に仮定する）などの「Anti-Drifting Sampling」を導入している 。これは、自己回帰的な生成に伴う誤差の蓄積（Exposure Bias）を、双方向的な情報の制約によって補正するものである。
3.2 「変化の抑制」という副作用の発生機序
しかし、この高度に最適化された記憶構造こそが、意図的な変化を阻害する要因となる。
固定的な重要度評価: 現行のFramePackでは、フレームの重要度が主に「時間的距離」で決定される。これは「シーンの変わり目」においても適用されるため、カット直前のフレーム（前のシーンの残像）が高い重要度を持ってしまい、次のシーンの生成に干渉する（ゴーストの発生やシーンの混ざり合い）。
アンチドリフトの過剰適用: ドリフト防止機構は、急激な画素の変化を「エラー」として検知し、平滑化しようとする傾向がある。シーンチェンジのような急激な変化は、アルゴリズム上は「最大級のドリフト」と見なされやすく、結果として変化が抑制され、前のシーンが「モーフィング」して次のシーンに繋がるような不自然な遷移を生む。
トークンの意味的固着: 圧縮されたコンテキスト内には、前のシーンの支配的なオブジェクトやスタイルの特徴量が強くエンコードされている。新しいプロンプトが入力されても、KVキャッシュ（Key-Value Cache）内の支配的な特徴量がアテンションを吸い寄せ、新しい概念の生成を妨げる。

第4章：シーン遷移（Scene Transition）における未解決問題
シーン遷移は、動画生成モデルが「記憶」をどのように扱うかをテストする究極のベンチマークである。ここでは、特に「ハードカット（Hard Cut）」における課題と、最新の研究動向を分析する。
4.1 アテンションシンク（Attention Sink）とシンク崩壊（Sink-Collapse）
自己回帰的モデルにおける長尺生成の失敗モードとして、最近の研究「LoL (Longer than Longer)」は「シンク崩壊（Sink-Collapse）」を報告している 。
現象: 生成が進むにつれて、モデルが初期のフレーム（開始フレームや特定の「シンク」フレーム）に過度のアテンションを向け始め、生成内容が初期状態にリセットされたり、ループしたりする現象。
原因: これは、RoPE（Rotary Position Embedding）の周期的構造と、マルチヘッドアテンションの相互作用における不整合に起因する。特定のアテンションヘッドが初期フレームの特徴量に「ロック」されてしまい、時間の経過とともにその結合が強固になることで発生する 。
変化への影響: シンク崩壊は、意図しない「変化の抑制」の極端な例である。モデルは新しい時間を刻んでいるにもかかわらず、視覚的には過去（シンクフレーム）に囚われ続ける。
理論的ギャップ: RoPEの基本周波数やアテンションヘッドの分散（Jitter）が、記憶の「固着」と「流動」にどう影響するかの数理的な境界条件が未解明である。
4.2 トランジション認識の欠如とTAVデータセット
多くの動画生成モデルは、連続したクリップの学習に特化しており、「シーンの切り替わり」を明示的に学習していない。このため、プロンプトで「森から海へ切り替わる」と指示しても、モデルはそれを「森が海に変身する」映像として生成してしまう。
TAV (Transition-Aware Video) の試み: この問題に対し、遷移を含むビデオクリップと、シーン分割を明示したキャプションからなるデータセット「TAV」を用いた事後学習（Post-Training）が提案されている 。
成果: TAVによる学習を行うことで、モデルはプロンプトに含まれる「シーン数」の含意を理解し、明示的な遷移（カット）を生成できるようになることが示されている 。
経験的ギャップ: FramePackのような圧縮コンテキストモデルにおいて、TAVのような遷移学習が有効かどうかの検証は行われていない。圧縮されたコンテキストが、急激な遷移情報を保持できるか、あるいはノイズとして捨ててしまうかは不明である。
4.3 SkyReels-V3におけるショットスイッチング
最新のSkyReels-V3は、「ショットスイッチング（Shot Switching）」機能を搭載し、プロの映画制作のようなカット割りを実現している 。
手法: マルチモーダルなインコンテキスト学習（In-Context Learning）を採用し、視覚的な参照画像、動画、音声、テキストを統合して「文脈」を推論する。これにより、単なる連続生成だけでなく、「Cut-In（インサート）」や「Cut-Out」といった不連続な遷移を制御可能にしている 。
示唆: SkyReelsのアプローチは、モデルに「編集」の概念を理解させるには、単なるテキストプロンプトだけでなく、構造化された「遷移パターン」を学習させる必要があることを示唆している。

第5章：選択的忘却（Selective Forgetting）とオブジェクト消失
「変化の抑制」を克服するためには、モデルに「何を覚えているべきか」だけでなく「何を忘れるべきか」を能動的に制御させる必要がある。これが選択的忘却（Selective Forgetting）の領域である。
5.1 概念のアンラーニング（Concept Unlearning）と推論時の忘却
選択的忘却には、大きく分けて「モデルの重みからの削除（Unlearning）」と「推論時のアテンション制御（Inference-time Suppression）」の二つのアプローチがある。
重みレベルの忘却（SAeUron, ROSE）
SAeUron: スパースオートエンコーダ（SAE）を用いて、拡散モデル内の特定の概念（例：著作権物、有害コンテンツ）に対応する特徴量を特定し、削除する手法 。
ROSE (Remove Objects with Side Effects): 動画内の特定のオブジェクトを削除するだけでなく、その「副作用（影、反射）」まで含めて環境から消去するフレームワーク 。合成データを用いて「物体がある状態」と「ない状態」のペアを学習させることで実現している。
これらの手法は「特定の概念を永久に忘れる」ことには有効だが、動画のストーリー展開の中で「一時的に忘れる（シーンから退場させる）」という動的な制御には適応しにくい。
推論レベルの忘却（Attention Masking）
Dynamic Mask & Refusal Vectors: 推論時のアテンションマップに動的なマスクを適用したり、特定の概念を否定するベクトル（Refusal Vector）を注入することで、生成プロセスから特定の要素を排除する 。
課題: これを動画の時系列の中で、特定のタイミング（消失シーン）でのみ発動させる制御機構が、現在のFramePack等のアーキテクチャには欠けている。
知識的ギャップ: 動的なシーン展開の中で、特定のオブジェクトIDのみを「選択的に」コンテキストからパージ（追放）しつつ、背景や画風は維持する、という「部分的な文脈リセット」のメカニズムが確立されていない。
5.2 オブジェクト消失の失敗モード
現在の動画生成モデルにおける典型的な失敗例として、「オブジェクトが消えない」あるいは「消えた後にゴーストとして再出現する」現象が挙げられる 。 MOSEv2ベンチマークなどでは、オブジェクトの消失と再出現を含む複雑なシーンでの追跡・生成能力が評価されているが、多くのモデルは「消失＝情報のロスト」と捉え、再出現時に一貫性を保てないか、逆に「消失」自体を拒絶してオブジェクトを描画し続ける傾向がある 。これは、モデルが「見えなくなった（Occlusion/Disappearance）」状態と「存在しなくなった（Non-existence）」状態を区別できていないことに起因する。

第6章：動的メモリ管理とKVキャッシュの最適化
Transformerモデルの「記憶」の実体は、KVキャッシュ（Key-Value Cache）である。このキャッシュの管理（Eviction Policy：どの情報を捨て、何を残すか）こそが、変化の抑制を制御する直接的なレバーとなる。
6.1 KVキャッシュの選別（Eviction）戦略
従来のKVキャッシュ管理は、FIFO（先入れ先出し）や単純なトークン重要度に基づくものであったが、これらは「意味的な変化」に対応できない。
手法
メカニズム
長尺動画生成における課題
PyramidalKV / SnapKV
重要度の低いトークンを間引く、あるいは階層的に圧縮する。
視覚的な詳細（高周波情報）は保持されるが、意味的な文脈（ストーリー）の切り替えに対応できない。
Ada-KV
アテンションヘッドごとに適応的なキャッシュ予算を割り当てる。
ヘッドごとの役割（スタイル維持、動作生成など）に応じたメモリ管理が可能だが、動的なシーン変更への追従性は未知数。
MadaKV
モダリティ（テキスト vs 画像）ごとの重要度差を考慮し、適応的に選別する。
テキストプロンプトの変更（シーン転換指示）を敏感に察知し、視覚トークンをリフレッシュする可能性を持つが、動画モデルへの適用は未開拓。
ChunkKV
文脈的に重要な「チャンク（塊）」を保持する。
シーンの核となる要素（主語、述語、目的語に対応する視覚情報）を保持しうるが、シーン遷移時にはこれが逆に「変化の抑制」要因となるリスクがある。

6.2 セマンティック・リキャッシング（Semantic Re-Caching）
最も有望なアプローチの一つとして、「セマンティック・リキャッシング」が挙げられる 。
概念: プロンプトが切り替わった瞬間に、既存のKVキャッシュを一度フラッシュ（破棄）するのではなく、新しいプロンプトと過去の生成フレームを用いて「再エンコード」する。
効果: これにより、前のプロンプト由来の「残存セマンティクス（Residual Semantics）」を除去しつつ、映像としての連続性（モーションや画質）のみを継承した新しいキャッシュを構築できる。
方法論的ギャップ: FramePackのような圧縮コンテキストモデルにおいて、このリキャッシングをどのように実装するかが課題である。圧縮されたトークンは元の画素情報を持たないため、再エンコードのソースとして使うには情報の劣化が激しい可能性がある。

第7章：リサーチギャップの統合的分析
以上の調査から、長尺動画生成における「記憶による変化の抑制」には、以下の4つの主要なリサーチギャップが存在すると結論付けられる。
Gap 1: 方法論的ギャップ - 「シーン認識型」圧縮スケジュールの欠如
現行のFramePackは、フレームの重要度を幾何級数的あるいは時間的距離で決定しており、映像の「内容」や「意味的区切り」を考慮していない 。
詳細: シーンが変化する瞬間（Transition Point）であっても、モデルは直前のフレームを「最も重要」として高解像度で保持しようとする。これにより、前のシーンの残像が次のシーンに漏れ出す。
必要性: 入力プロンプトの変化や映像のエントロピー変化を検知し、圧縮率や保持するフレームを動的に変更する「シーン認識型（Scene-Aware）」のスケジューリング手法が必要である。
Gap 2: 知識的ギャップ - 「意味的慣性（Semantic Inertia）」の定量的理解
ドリフト（画質の劣化）については多くの指標（FVD等）があるが、モデルがどれだけ「過去の意味に引きずられるか」を測定する指標や理論的枠組みが存在しない。
詳細: アンチドリフト機構が、正当なシーン遷移を「ドリフト」と誤認して抑制してしまうメカニズム（誤検知のダイナミクス）についての知見が不足している。
必要性: 「意味的慣性」を定量化し、どの程度のアテンション強度が変化を阻害するかの閾値を特定する研究が必要である。
Gap 3: 経験的ギャップ - 「意図的忘却」のベンチマーク不在
既存のベンチマーク（VBench, LongBench）は、いかに長く・正確に覚えているかを評価するものであり、いかに「適切に忘れるか」を評価していない 。
詳細: 「赤いボールを消せ」「背景を夜に変えろ」といったネガティブ制約（Negative Constraints）や状態変化を含むプロンプトに対する追従性を、長尺生成の中で評価する標準的なテストセットが存在しない。
必要性: プロンプトの切り替えから映像が実際に変化するまでの「ラグ（遅延）」や、変化後の「残存アーティファクト」を測定する新しい評価指標が必要である。
Gap 4: 理論的ギャップ - RoPEにおける「記憶と変化の平衡点」
LoLの研究が示したように、RoPEの設計が記憶の固着（Sink-Collapse）に直結している 。
詳細: 無限の長さを生成するためには、位置エンコーディングが循環または相対的である必要があるが、これが「過去への回帰」を誘発する。
必要性: マルチヘッドアテンションにおいて、各ヘッドが「過去の維持」と「未来の探索」にどう役割分担すべきか、その周波数特性や分散（Jitter）の数理的最適解が未解明である。
