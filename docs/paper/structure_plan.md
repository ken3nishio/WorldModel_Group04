# 論文構成案: 大規模動画生成モデルにおける時間的慣性の適応的制御

## 1. タイトル
大規模動画生成モデルにおける「時間的慣性」の適応的制御：
Adaptive CFGとTemporal Unlearningによる動的状態遷移の実現

## 2. メンバーとその所属
（ユーザー情報に基づき記入）

## 3. アブストラクト
*   **背景**: HunyuanVideo等の最新動画生成モデルは、極めて高い時間的一貫性を実現している。
*   **課題**: その反面、物体が消失したり、静止状態から急激に動く（バク転など）ような「非連続的な変化」を生成しようとすると、初期状態を維持しようとする慣性が働き、動作が生成されない "Static Death"（静的死）現象が発生する。
*   **提案**: 推論時のハイパーパラメータ制御により、この「時間的慣性」を動的に調整する手法を提案する。具体的には、(1)初期推力を与えるAdaptive CFG ($\beta$)、(2)介入の減衰を制御するPower ($p$)、(3)過去の記憶を曖昧にするTemporal Blurを導入する。
*   **結果**: これらのパラメータを最適化することで、映像の崩壊（Collapse）を防ぎつつ、モデルの静的バイアスを打破し、動的なアクション生成が可能であることを実証した。

## 4. 研究背景・目的
### 背景
*   拡散モデルを用いた動画生成は、短いクリップから長時間の生成へと進化している。
*   HunyuanVideoやFramePackは、過去のフレーム情報を強く参照することで、フリッカー（ちらつき）のない滑らかな映像を実現している。

### 課題: "Static Death"
*   この「滑らかさ」へのバイアスが、急激な変化を阻害している。
*   例: 「バク転」を指示しても、モデルは「立っている人物」の画像を一貫して生成し続け、わずかに揺れる程度（Robot Dancing）で終わる。
*   これを我々は、モデルの**「時間的慣性（Temporal Inertia）」過剰**による "Static Death" と定義する。

### 目的
*   モデルの再学習（Fine-tuning）を行わず、推論時の計算コストも最小限に抑えつつ、この慣性を制御可能にすること。
*   「一貫性（Consistency）」と「可塑性（Plasticity）」のトレードオフを、ユーザーが意図的に操作できるパラメータを提供すること。

## 5. 関連研究
*   **一貫性向上手法**: ControlNetやAnimateDiffなど。これらは主に「動きを安定させる」方向に注力しており、「動きすぎるのを止める」研究が多い。本研究は逆に「止まっているものを動かす」点に独自性がある。
*   **推論時介入**: Dynamic CFGやFreeInit。これらは画質向上を主眼としているが、本研究は「アクションの意味的整合性」に焦点を当てる。

## 6. 提案手法（取り組んだこと）
"Static Death" を克服するための3つの仮説に基づき、パラメータを導入した。

### (1) Adaptive CFG Beta ($\beta$): "Impulse"
*   **仮説**: 静止摩擦を超えるには、初期に強力なエネルギーが必要である。
*   **手法**: 生成プロセスの初期段階（高ノイズ時）において、CFGスケールを通常の1.5倍〜2倍にブーストする（負のBeta）。これにより、モデルを強制的に「動的モード」へ遷移させる。

### (2) Decay Power ($p$): "Structural Integrity"
*   **仮説**: 強い力をかけ続けると、映像が崩壊する。
*   **手法**: ステップが進むにつれて介入効果を減衰させる関数 $w(\sigma) = w_{base} + \alpha \sigma^p$ を導入。
*   **工夫**: $p$ を大きく（例: 2.0）設定し、介入を「一瞬の衝撃（インパルス）」に限定することで、後半のフレームにおける構造崩壊を防ぐ。

### (3) Temporal Context Unlearning (Blur): "Forgetting"
*   **仮説**: モデルが動かないのは、過去の自分（立っている姿）を見すぎているからである。
*   **手法**: Self-AttentionのKey/Valueキャッシュに対し、時間方向のガウシアンブラーを適用。
*   **効果**: 直前のフレームの詳細情報を意図的に曖昧にすることで、モデルの「記憶」を弱め、新しい状態（空中にいる姿など）への書き換えを許容させる。

## 7. 実験・考察
### 実験設定
*   **タスク**: Backflip（バク転）、Disappearance（消失）。いずれも「状態の急変」を伴う難易度の高いタスク。
*   **評価指標**:
    *   **LPIPS**: 映像の一貫性（低いほど安定）。
    *   **VideoMAE Score**: アクションの成立度（高いほど良い）。

### 結果と比較
以下の3条件で比較を行った。
1.  **Baseline ($\beta=0$)**: LPIPSは良いが、VideoMAEはほぼ0。（Static Death）
2.  **Forced ($\beta=-1.0$)**: VideoMAEは上がらず、LPIPSが悪化。（崩壊）
3.  **Ours ($\beta=0.9, p=2.0$)**: LPIPSを維持しつつ、VideoMAEが大幅向上。（成功）

### 考察
*   **Powerパラメータの重要性**: 単に強く推す（Beta）だけでは映像が壊れる。Powerによる「引き際」の制御が、成功の鍵であった。
*   **トレードオフの制御**: 提案手法により、一貫性を犠牲にすることなく、必要な可塑性を引き出す「スイートスポット」を発見できた。

## 8. まとめ
*   動画生成における「時間的慣性」を制御する包括的なフレームワーク (FAHC) を提案した。
*   適応的なCFG制御と時間的忘却を組み合わせることで、Training-freeで動的なアクション生成が可能であることを示した。
